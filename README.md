# Referential Language Game with Compositional Inputs

## Introduction

### Motivation

### Literature

## Methods: Reinforce with EGG
EGG (Emergence of lanGuage in Games) is a toolkit for implementing referential language games. In each of these games a communications protocol (language) emerges from the interaction of two agents. The first agent (sender) encodes an input (for example an image) into a sentence with a fixed maximal length, that consists of symbols from a discrete alphabet. This message is the input of the receiver agent. In one version the task for the receiver is then, to either choose the input image from a set that additionally includes distractor images (discrimination). In the version, that is implemented here, the task of the receiver is to recreate the original image (reconstruction).

The images consist of 100x100 pixels, with three colour channels, each. The content of the images can be described in a vector, consisting of: x-coordinate, y-coordinate, shape, size, color, outline. Each of these values is normalize to the interval \[0, 1\]. The shape can be one of three categories (circle, square, triangle). For simplicity, the vector representation assumes an ordinal scaling and maps these three categories to the values 0, 0.5 and 1.0, respectively. 
This vector representation is used as targets, for pretraining a vision module for the sender agent. The vision module mainly consists of convolution layers. After training, the final classification layer is left out and the models weights are kept fixed. That way a pretrained vision module serves as a mapping from images to abstract features, that should in theary contain all necessary information for the sender, in order to describe the images from which it came. The amount of abstract features, that the vision module extracts is the size 


## Implementation

## Results

## Discussion


## Refs

Description:

1. Data: Our data consists (at this point) of 100x100 pixel images, depicting a single shape. Each shape has the following features:

- posx, posy: x and y coordinates

- shape: one of three categories

- size: size in pixel

- color: one value, based on a colormap from matplotlib

- outline: boolean, if there is an outline around the shapes

2. Task: Reconstruction

The task of the sender agent will be to encode the image into a message. The message is then given to the receiver agent, who reconstructs the image based on the message. Alternatively, the task could be discrimination. Here, the receiver must select the original image from a set of images based on the received message. (at this point, we tend to do the first version)

3. The sender agents architecture: CNN + GRU

A vision module (CNN) for the sender will be pretrained on the images. The features generated by the CNN will serve as input for the GRU, which will generate the message.

4. The receiver agents architecture: GRU + Fully connected layer

The GRU will receive the message and it’s output will serve as an input to the dense layer. The dense layer will be of the same size and dimensionality as the original input images.

5. The training

Currently, we use REINFORCE to train the agents. We are going to change that to a more advanced actor-critic based algorithm.

6. Evaluation

Finally, we will evaluate the generated messages. We will compare the messages generated by the agents trained with REINFORCE to the messages of the agents trained with an Actor-Critic based algorithm The vector representation that underlies the data will enable us to analyze the languages capabilities regarding compositionality (is a "green triangle" a combination of "green" and "triangle" or is it a completely new concept). Maybe we will use an performance measure from the paper “The Grammar of Emergent Languages”. We will draw references to the paper we have been talking about.